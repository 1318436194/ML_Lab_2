# 2025《机器学习》实验指导书

## 实验：逻辑回归和支持向量机

### 实验目的

1.对比理解梯度下降和批量随机梯度下降的区别与联系。

2.对比理解逻辑回归和线性分类的区别与联系。

3.进一步理解SVM的原理并在较大数据上实践。

### 数据集

* 实验使用的是LIBSVM Data的中的`a9a`数据，包含32561 / 16281(testing)个样本，每个样本有123/123(testing)个属性。在读取数据时可能会出现维度不对的问题，是因为数据最后列全为零而被忽略，可以在数据集文件后面自行添加后再读取，也可在读取数据集时指定`n_features=123`来解决。
* 训练数据位于项目目录中的`datesets/a9a.txt`，测试数据位于项目目录中的`datesets/a9a.t.txt`

### 实验环境

python3，包含python包: sklearn，numpy，jupyter，matplotlib等。

### 提交内容

实验报告与程序代码

### 实验形式

个人独立完成

### 实验步骤

本次实验代码及画图均在项目目录中的`src/`目录中使用Python编写`.py`文件完成（使用中文注释），并使用jupyter notebook中的代码段格式展示结果，因为后续会copy到`.ipynb`文件中运行。

#### 逻辑回归与批量随机梯度下降

1.读取实验训练集和验证集

2.逻辑回归模型参数初始化(可以考虑全零初始化，随机初始化或者正态分布初始化)。

3.选择Loss函数及对其求导，过程详见课件ppt。

4.自行确定batch_size大小，随机取出部分样本，求得部分样本对Loss函数的梯度

5.使用SGD优化方法更新参数模型，鼓励额外尝试Adam优化方法。

6.选择合适的阈值，将验证集中计算结果大于阈值的标记为正类，反之为负类。在验证集上测试并得到Loss函数值。

7.重复步骤4-6若干次，画出 随迭代次数的变化图。

#### 线性分类与批量随机梯度下降

1.读取实验训练集和验证集。

2.支持向量机模型参数初始化(可以考虑全零初始化，随机初始化或者正态分布初始化)。

3.选择Loss函数并对其求导，过程详见课件ppt。可以考虑多种loss函数。

4.自行确定batch_size大小，随机取出部分样本，求得部分样本对Loss函数的梯度。

5.使用SGD优化方法更新参数模型，鼓励额外尝试Adam优化方法。

6.选择合适的阈值，将验证集中计算结果大于阈值的标记为正类，反之为负类。在验证集上测试并得到Loss函数值。

7.重复步骤4-6若干次，画出随迭代次数的变化图。

### 任务要求

* 整理两次实验结果并完成实验报告

* $LaTex$实验报告模版位于项目目录中的`report/英文实验报告模板-LaTex`

* 请使用英文模板撰写。